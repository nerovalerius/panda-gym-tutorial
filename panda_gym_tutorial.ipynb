{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applied Reinforcement Learning - Tutorial - Panda-Gym\n",
    "### [Armin Niedermueller](https://github.com/nerovalerius)\n",
    "### Salzburg University of Applied Sciences"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covered Topics\n",
    "* Panda-Gym Introduction\n",
    "    * Franka Panda Robot\n",
    "    * Setup\n",
    "* Example Environment - Panda Reach\n",
    "* Create a custom robot\n",
    "* Create a custom task with obstacles in the scene\n",
    "* Custom a custom environment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Panda-Gym Introduction\n",
    "Panda-Gym is a reinforcement learning environment for the Franka Emika Panda robot. It is based on the OpenAI Gym framework and provides a set of tasks that can be used to train reinforcement learning agents. The tasks are based on the PyBullet physics engine and can be used to train agents for real-world applications. The environment is designed to be easy to use and extend. It is also possible to create custom robots, environments and tasks.\n",
    "A detailed documentation can be found [here](https://panda-gym.readthedocs.io/en/latest/) and their paper can be cited as folows:\n",
    "```\n",
    "@article{gallouedec2021pandagym,\n",
    "  title        = {{panda-gym: Open-Source Goal-Conditioned Environments for Robotic Learning}},\n",
    "  author       = {Gallou{\\'e}dec, Quentin and Cazin, Nicolas and Dellandr{\\'e}a, Emmanuel and Chen, Liming},\n",
    "  year         = 2021,\n",
    "  journal      = {4th Robot Learning Workshop: Self-Supervised and Lifelong Learning at NeurIPS},\n",
    "}\n",
    "```\n",
    "\n",
    "#### Franka Panda Robot\n",
    "Panda is a collaborative robot with 7 degrees of freedom developed by [FRANKA EMIKA](https://www.franka.de/).\n",
    "It can be programmed directly with a graphical user interface or with the Robot Operating System 1 & 2 (C++, MoveIt!, Rviz and so on).\n",
    "The torque sensors on it's 7 seven axes make this robot arm so sensitive, that it even stops at a balloon.\n",
    "It works at a very high precision as well as stability, which makes it a perfect tool for research and development.\n",
    "\n",
    "<img src=\"images/franka_panda.png\"  width=\"35%\"> \\\n",
    "Image source: [LINK](https://github.com/nerovalerius/collision_avoidance/blob/master/BAC2_niedermueller.pdf)\n",
    "\n",
    "I worked with the Panda robot for my bachelor thesis, where i used two 3D stereo cameras to enable collision avoidance for the robot arm. The robot was able to avoid obstacles while reaching a target. The code and results can be found [here](https://github.com/nerovalerius/collision_avoidance) and [here](https://www.youtube.com/watch?v=LQPS--bnvQY)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup\n",
    "Before we are able to start programming, we need to prepare our programming environment.\n",
    "\n",
    "##### Linux\n",
    "First of all, we create a virtual environment for our undertaking, in order to avoid conflicts with other projects.\n",
    "We use the conda package manager to create a virtual environment. If you are not familiar with conda, you can find a tutorial [here](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html).\n",
    "\n",
    "First, download and install miniconda.\n",
    "```\n",
    "wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh \\\n",
    "    && bash Miniconda3-latest-Linux-x86_64.sh -b \\\n",
    "    && rm Miniconda3-latest-Linux-x86_64.sh\n",
    "```\n",
    "Follow the instructions on the terminal and also initialize conda for your current shell.\n",
    "```\n",
    "conda init bash\n",
    "```\n",
    "Now, create a new environment and activate it.\n",
    "```\n",
    "conda create -n panda-gym-tutorial python=3.9\n",
    "conda activate panda-gym-tutorial\n",
    "```\n",
    "\n",
    "##### Window\n",
    "1. Install [Anaconda](https://www.anaconda.com/)\n",
    "2. Install [VS Code](https://code.visualstudio.com/).\\\n",
    "    a. Install [Python Extension](https://marketplace.visualstudio.com/items?itemName=ms-python.python) for VS Code\\\n",
    "    b. Install [Jupyter Extension](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter) for VS Code\n",
    "\n",
    "For panda-gym, there is currently no conda package available. Therefore, we need to install it with pip.\n",
    "Furthermore, we can install numpngw to store the rendered images as animated png files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install panda-gym\n",
    "%pip3 install numpngw"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Environment - Panda Reach\n",
    "Panda-Gym defines for each task a separate environment. Let's take a look at the environment for the **Panda Reach** environment, where the robot has to reach a target position with its end-effector:\n",
    "\n",
    "```\n",
    "import numpy as np\n",
    "from panda_gym.envs.core import RobotTaskEnv\n",
    "from panda_gym.envs.robots.panda import Panda\n",
    "from panda_gym.envs.tasks.reach import Reach\n",
    "\n",
    "class PandaReachEnv(RobotTaskEnv):\n",
    "    \"\"\"Reach task wih Panda robot.\n",
    "    Args:\n",
    "        render (bool, optional): Activate rendering. Defaults to False.\n",
    "        reward_type (str, optional): \"sparse\" or \"dense\". Defaults to \"sparse\".\n",
    "        control_type (str, optional): \"ee\" to control end-effector position or \"joints\" to control joint values.\n",
    "            Defaults to \"ee\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, render: bool = False, reward_type: str = \"sparse\", control_type: str = \"ee\") -> None:\n",
    "        # use PyBullet as simulation backend\n",
    "        sim = PyBullet(render=render)\n",
    "        # use Panda robot, define its control type and initial position\n",
    "        robot = Panda(sim, block_gripper=True, base_position=np.array([-0.6, 0.0, 0.0]), control_type=control_type)\n",
    "        # use Reach task, define its reward type and initial end-effector position\n",
    "        task = Reach(sim, reward_type=reward_type, get_ee_position=robot.get_ee_position)\n",
    "        super().__init__(robot, task)\n",
    "```\n",
    "\n",
    "We define PyBullet as our physics engine for robotics. It is used to simulate and render the robot and the environment.\n",
    "\n",
    "The robot is defined in [/panda_gym/envs/robots/panda](https://github.com/qgallouedec/panda-gym/blob/master/panda_gym/envs/robots/panda.py). \\\n",
    "Here, you can find all necessary physics parameters (such as friction) and functions (such as set_action).\n",
    "\n",
    "Furthermore, the task is defined as Reach task, defined in [panda_gym/envs/tasks/reach.py](https://github.com/qgallouedec/panda-gym/blob/master/panda_gym/envs/tasks/reach.py).\\\n",
    "Inside this file, the 3D environment (such as the table) is defined and the reward is computed. \n",
    "\n",
    "Now, three parameters can be set in the environment:\n",
    "* **render:** activate or deactivate the rendering of the environment\n",
    "* **reward_type:**\n",
    "    * sparse: reward is 1 if the target is reached and 0 otherwise\n",
    "    * dense: reward is the distance between the target and the end-effector\n",
    "* **control_type:** actions should either control the robot's:\n",
    "    * end-effector position\n",
    "    * or joint values\n",
    "\n",
    "#### Code and Animation\n",
    "<img src=\"images/reach.png\"  width=\"35%\"> \n",
    "\n",
    "First, we create \"PandaReach-v3\" environment and set render to True, to see what the robot is learning. Then, we reset the environment, define our number of maximum number of episodes and let the robot take actions provided by our policy. After each step, we check if the episode is done and if so, we reset the environment. \n",
    "\n",
    "\n",
    "Beside the actual reinforcement learning, we also create an animation of the robot's learning process by storing the rendered images inside a png file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# Task: Panda Reach               #\n",
    "###################################\n",
    "\n",
    "import gymnasium as gym\n",
    "import panda_gym\n",
    "from tqdm import tqdm\n",
    "from numpngw import write_apng\n",
    "\n",
    "# please choose one of the following render modes\n",
    "render_mode = 'human'       # opens OpenGL window for rendering\n",
    "#render_mode = 'rgb_array'  # returns RGB image as numpy array, if the render should be stored as animated png\n",
    "\n",
    "# create environment and activate rendering\n",
    "if render_mode == 'rgb_array':\n",
    "    images = [] # array to store images\n",
    "\n",
    "env = gym.make(\"PandaReach-v3\", render_mode=render_mode)\n",
    "\n",
    "# define low frame rate for rendering to reduce computational load\n",
    "env.metadata['render_fps'] = 24\n",
    "\n",
    "# reset environment and get initial observation (either state of the joints or the end effector position)\n",
    "observation, info = env.reset()\n",
    "# define maximum nuber of episodes\n",
    "max_steps = 10000\n",
    "\n",
    "# run simulation \n",
    "for step in tqdm(range(max_steps)):\n",
    "    # take action as defined by our policy\n",
    "    action = env.action_space.sample()\n",
    "    \n",
    "    # execute action and get new observation, reward, termination flag and additional info\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    # add each image to our array for each step to create an animation afterwards\n",
    "    if render_mode == 'rgb_array':\n",
    "        images.append(env.render())\n",
    "\n",
    "    # when the episode is terminated, reset the environment\n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "\n",
    "env.close()\n",
    "\n",
    "if render_mode == 'rgb_array':\n",
    "    # save animation\n",
    "    print(\"Saving animation...\")\n",
    "    write_apng('images/reach.png', images, delay = 5)\n",
    "print(\"finished\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a custom robot\n",
    "This section follows loosely the [panda-gym tutorial](https://panda-gym.readthedocs.io/en/latest/custom/custom_robot.html) for creating a custom robot. \n",
    "\n",
    "#### Create URDF\n",
    "First, we need to create a [URDF](http://wiki.ros.org/urdf) (Unified Robot Description Format) file for our robot. \n",
    "URDF is an XML file format used in ROS to describe all elements of a robot. It is used to define the robot's kinematic and dynamic structure, as well as its physical properties.\n",
    "Luckily, there are some tools available to visualize URDF files while writing them. For example [URDF Modeler](https://mymodelrobot.appspot.com/5629499534213120), which we will use in this tutorial.\n",
    "\n",
    "A URDF file consists of several parts:\n",
    "* **robot:** the root element of the file\n",
    "* **link:** a rigid body\n",
    "* **joint:** a joint connecting two links\n",
    "\n",
    "and some optional parts:\n",
    "* **material:** defines the color of a link\n",
    "* **transmission:** defines the transmission between a joint and a motor\n",
    "\n",
    "We begin by defining the robot's name and the base link. The base link is the link that is fixed to the ground. In our case, we will use the base link to define the robot's initial position.\n",
    "\n",
    "```\n",
    "  \t<link name=\"link0\"> <!--base_link -->\n",
    "\t\t<visual>\n",
    "\t\t\t<origin xyz=\"0 0 0\" rpy=\"0 0 0\"/>\n",
    "\t\t\t<geometry>\n",
    "\t\t\t\t<cylinder radius=\"0.1\" length=\"0.05\"/>\n",
    "\t\t\t</geometry>\n",
    "\t     \t<material name=\"Cyan3\">\n",
    "\t\t\t\t<color rgba=\"0 0.5 0.5 0\"/>\n",
    "\t\t\t</material>\n",
    "\t   </visual>\n",
    "\t</link>\n",
    "```\n",
    "\n",
    "This is a squared base with dimensions 0.3 x 0.3 x 0.05 m. The origin of the visual element is defined by the xyz and rpy attributes. The xyz attribute defines the position of the origin in the link's frame. The rpy attribute defines the orientation of the origin in the link's frame. The orientation is defined by the roll, pitch and yaw angles. The roll angle is the rotation around the x-axis, the pitch angle is the rotation around the y-axis and the yaw angle is the rotation around the z-axis. The roll, pitch and yaw angles are defined in radians. The origin of the link's frame is defined by the xyz and rpy attributes of the link element.\n",
    "\n",
    "The first joint connects the first arm part to the base_link, the type is revolute, which means that the joint is a hinge joint.\n",
    "\n",
    "```\n",
    "\t<joint name=\"joint0\" type=\"revolute\">  <!-- base -->\n",
    "    \t<parent link=\"link0\"/>\n",
    "    \t<child link=\"link1\"/>\n",
    "    \t<origin xyz=\"0 0 0.10\" rpy=\"0 0 0\"/>\n",
    "    \t<axis xyz=\"0 0 1\"/>\n",
    "    \t<limit lower=\"-0.6\" upper=\"0.6\" effort=\"0\" velocity=\"3\"/>\n",
    "  \t</joint>\n",
    "```\n",
    "\n",
    "We now have our base defined. For each part of our robot, we define a link for the arm part itself, which consists of a sphere link connected with a fixed joint to an arm link:\n",
    "\n",
    "```\t\n",
    "  \t<link name=\"link1\"> <!-- cylinder0 -->\n",
    "\t\t<visual>\n",
    "\t\t\t<origin xyz=\"0 0 0\" rpy=\"0 0 0\"/>\n",
    "\t\t\t<geometry>\n",
    "\t\t\t\t<cylinder radius=\"0.05\" length=\"0.2\"/>\n",
    "\t\t\t</geometry>\n",
    "\t     \t<material name=\"Yellow2\">\n",
    "\t\t\t\t<color rgba=\"0.8 0.8 0 1.0\"/>\n",
    "\t\t\t</material>\n",
    "\t   </visual>\n",
    "\t</link>\t\n",
    "\t\n",
    "\t<link name=\"link2\"> <!-- ball0 -->\n",
    "\t\t<visual>\n",
    "\t\t\t<origin xyz=\"0 0 0\" rpy=\"0 0 0\"/>\n",
    "\t\t\t<geometry>\n",
    "\t\t\t\t<sphere radius=\"0.052\"/>\n",
    "\t\t\t</geometry>\n",
    "\t\t\t<material name=\"Cyan1\">\n",
    "\t       \t\t<color rgba=\"0 0.9 0.9 1.0\"/>\n",
    "\t\t\t</material>\n",
    "\t   </visual>\n",
    "\t</link>\n",
    "\n",
    " \t<joint name=\"joint1\" type=\"revolute\">  <!-- cylinder0 -->\n",
    "    \t<parent link=\"link1\"/>\n",
    "    \t<child link=\"link2\"/>\n",
    "    \t<origin xyz=\"0 0 0.1\" rpy=\"0 0 0\"/>\n",
    "\t\t<limit lower=\"0.5\" upper=\"1.6\" effort=\"10\" velocity=\"3\"/>\n",
    "        <axis xyz=\"0 1 0\"/>\n",
    "\t</joint>\n",
    "\n",
    "```\n",
    "\n",
    "The sphere created is to connect the links more realistically. Not only the visual geometry is defined, but also the collision geometry, which is used to avoid collision with other parts in the environment and the robot parts itself. Typically, the geometric dimensions are the same as the visual dimensions.\n",
    "\n",
    "Between the arm links and the spheres of the next arm link, a movable joint is needed, such as:\n",
    "\n",
    "```\n",
    "<joint name=\"joint_2\" type=\"revolute\">\n",
    "    \t<parent link=\"link_1\"/>\n",
    "    \t<child link=\"jointlink_2\"/>\n",
    "    \t<origin xyz=\"0 0 0.1\" rpy=\"0 0 0\"/>\n",
    "\t\t<limit lower=\"-1.57\" upper=\"1.57\" effort=\"10\" velocity=\"3\"/>\n",
    "        <axis xyz=\"0 1 0\"/>\n",
    "\t</joint>\n",
    "``` \n",
    "\n",
    "We define a revolute joint, with the limits of -pi/2 to pi/2 and rotation around the y-axis. The effort and velocity limits are defined in Nm and rad/s, respectively. The effort limit is the maximum torque that can be applied to the joint. The velocity limit is the maximum angular velocity that can be applied to the joint.\n",
    "\n",
    "After building each links and joints onto each other, we place a gripper (or: end effector) on the last link of our robot, in order to let the robot grip objects.\n",
    "\n",
    "```\n",
    "    <link name=\"link8\"> <!-- gripper_base -->\n",
    "  ...\n",
    "    <visual>\n",
    "      <geometry>\n",
    "        <box size=\"0.105 .02 .025\"/>\n",
    "      </geometry>\n",
    "      <origin rpy=\"0 0 0\" xyz=\"0 -0.1 0\"/>\n",
    "      <material name=\"white\">\n",
    "        <color rgba=\"1 1 1 1\"/>\n",
    "      </material>\n",
    "    </visual>\n",
    "    ...\n",
    "</link>\n",
    "\n",
    "  <link name=\"link9\"> <!-- left_fingertip -->\n",
    "    ...\n",
    "    <visual>\n",
    "      <geometry>\n",
    "        <box size=\"0.025 .05 0.025\"/>\n",
    "      </geometry>\n",
    "      <origin rpy=\"0 0 0\" xyz=\"0 0 0\"/>\n",
    "      <material name=\"white\">\n",
    "        <color rgba=\"1 1 1 1\"/>\n",
    "      </material>\n",
    "    </visual>\n",
    "    ...\n",
    "  </link>\n",
    "\n",
    "    <link name=\"link10\"> <!-- right fingertip -->\n",
    "    ...\n",
    "    <visual>\n",
    "      <geometry>\n",
    "        <box size=\"0.025 .05 0.025\"/>\n",
    "      </geometry>\n",
    "      <origin rpy=\"0 0 0\" xyz=\"0 0 0\"/>\n",
    "      <material name=\"white\">\n",
    "        <color rgba=\"1 1 1 1\"/>\n",
    "      </material>\n",
    "    </visual>\n",
    "    ...\n",
    "  </link>\n",
    "  ```\n",
    "\n",
    "Our gripper has two fingertips, which can be moved to grip an object. How they move is, again, defined as joint:\n",
    "\n",
    "```\n",
    " \t<joint name=\"joint7\" type=\"revolute\">  <!-- gripper_base -->\n",
    "    \t<parent link=\"link7\"/>\n",
    "    \t<child link=\"link8\"/>\n",
    "    \t<origin xyz=\"0 0 0\" rpy=\"-1.5708 0  0\"/>\n",
    "        <axis xyz=\"0 1 0\"/>\n",
    "    \t<limit lower=\"-1.57\" upper=\"1.57\" effort=\"10\" velocity=\"3\"/>\n",
    "\t</joint>\n",
    " \n",
    "  <joint name=\"joint8\" type=\"prismatic\">  <!-- gripper_base_to_right_fingertip -->\n",
    "    <axis xyz=\"1 0 0\"/>\n",
    "    <limit effort=\"1.0\" lower=\"-0.03\" upper=\"0.0\" velocity=\"0.5\"/>\n",
    "    <parent link=\"link8\"/>\n",
    "    <child link=\"link9\"/>\n",
    "    <origin xyz=\"0.04 -0.135 -0.0\"/>\n",
    "  </joint>\n",
    "\n",
    "    <joint name=\"joint9\" type=\"prismatic\">  <!-- gripper_base_to_left_fingertip -->\n",
    "    <axis xyz=\"1 0 0\"/>\n",
    "    <limit effort=\"1.0\" lower=\"0\" upper=\"0.03\" velocity=\"0.5\"/>\n",
    "    <parent link=\"link8\"/>\n",
    "    <child link=\"link10\"/>\n",
    "    <origin xyz=\"-0.04 -0.135 0.0\"/>\n",
    "  </joint>\n",
    "```\n",
    "\n",
    "Please consider the complete file under [urdf/robot.urdf](urdf/robot.urdf). \n",
    "An Animation created with [URDF Modeler](https://mymodelrobot.appspot.com/5629499534213120) of the urdf file shows how our links and joints move:\n",
    "\n",
    "<img src=\"images/urdf_robot_animated.gif\"  width=\"35%\"> \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Python Class for the Robot\n",
    "You can find the complete code under [envs/robots/simple_robot.py](envs/robots/simple_robot.py).\\\n",
    "We follow the tutorial of [panda-gym](https://panda-gym.readthedocs.io/en/latest/custom/custom_robot.html).\n",
    "\n",
    "The [tutorial](https://panda-gym.readthedocs.io/en/latest/custom/custom_robot.html) shows a simple class for a robot, which has only one joint. We extend this class to our robot, which has 5 joints. \n",
    "\n",
    "##### Parameters for initialization\n",
    "\n",
    "We define our action space with 5 dimensions, which are the joint angles. The action space is defined as a Box, which is a continuous space. The action space is defined as:\n",
    "```\n",
    "n_action = 5   # 5 joints\n",
    "action_space = spaces.Box(-1.0, 1.0, shape=(n_action,), dtype=np.float32)\n",
    "```\n",
    "Then we define our robot's physiqe by loading its URDF file:\n",
    "```\n",
    "body_name=\"simple_robot\",\n",
    "file_name=\"C:/Users/crypt/Dokumente/GitHub/panda-gym-tutorial/urdf/simple_robot.urdf\",\n",
    "```\n",
    "The next thing is to define the joints which are used to control the robot. We load the joints as:\n",
    "```\n",
    "joint_indices=np.array([0, 1, 3, 5, 7]),\n",
    "```\n",
    "The joints must have the naming convention such as ``joint0'', ``joint1'', ``joint2'', etc. The joint indices are the indices of the joints in the URDF file. The first joint is the base joint, which is not used to control the robot. We only focus on the reach task, so we do not use the gripper and finger joints. Furthermore, the joint forces need to be defined. The joint forces are the maximum torque that can be applied to the joint. The joint forces are defined as:\n",
    "```\n",
    "joint_forces=np.array([40.0, 40.0, 40.0, 40.0, 40.0]),\n",
    "```\n",
    "Now, set the initial joint positions. The initial joint positions are defined as:\n",
    "```\n",
    "self.neutral_joint_values = np.array([0.00, 0.00, 0.00, 0.00, 0.00])\n",
    "```\n",
    "The End Effector is the last link of the robot. The End Effector is defined as:\n",
    "```\n",
    "self.ee_link = 8\n",
    "```\n",
    "\n",
    "##### Action Function\n",
    "The action function is the function which is called to move the robot. The action function is defined as:\n",
    "```\n",
    "def action(self, action):\n",
    "    self.set_joint_positions(action)\n",
    "```\n",
    "Some modifications are necessary to make everything work properly:\n",
    "First, we ensure that the action lies within our action space:\n",
    "```\n",
    "action = np.clip(action, self.action_space.low, self.action_space.high)\n",
    "```\n",
    "Then we get the current joint positions in order to calculate the new joint positions:\n",
    "```\n",
    "current_arm_joint_angles = np.array([self.get_joint_angle(joint=i) for i in range(5)])\n",
    "```\n",
    "The new joint positions are calculated as:\n",
    "```\n",
    "target_arm_angles = current_arm_joint_angles + action\n",
    "```\n",
    "Now, set the new joint positions:\n",
    "```\n",
    "self.control_joints(target_angles=target_arm_angles)\n",
    "```\n",
    "\n",
    "##### Get Status Functions\n",
    "The get status functions are used to get the current state of the robot. The get status functions are defined as:\n",
    "```\n",
    "    def get_obs(self) -> np.ndarray:\n",
    "        # end-effector position and velocity\n",
    "        ee_position = np.array(self.get_ee_position())\n",
    "        ee_velocity = np.array(self.get_ee_velocity())\n",
    "        # fingers opening\n",
    "\n",
    "        observation = np.concatenate((ee_position, ee_velocity))\n",
    "        return observation\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        self.set_joint_neutral()\n",
    "\n",
    "    def set_joint_neutral(self) -> None:\n",
    "        \"\"\"Set the robot to its neutral pose.\"\"\"\n",
    "        self.set_joint_angles(self.neutral_joint_values)\n",
    "\n",
    "    def get_ee_position(self) -> np.ndarray:\n",
    "        \"\"\"Returns the position of the ned-effector as (x, y, z)\"\"\"\n",
    "        return self.get_link_position(self.ee_link)\n",
    "\n",
    "    def get_ee_velocity(self) -> np.ndarray:\n",
    "        \"\"\"Returns the velocity of the end-effector as (vx, vy, vz)\"\"\"\n",
    "        return self.get_link_velocity(self.ee_link)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restricting the action space\n",
    "\n",
    "The robot may have too much freedom of movement. This can result in the robot moving in a way that is not desired, e.g. the robot may move its arm in a way that it collides with the table. Or the algorithm may not be able to learn the task, because the action space is simply too large.\n",
    "\n",
    "We can restrict the action space by defining a maximum joint angles inside the URDF file.\n",
    "\n",
    "At first, load your URDF file into the[ Online URDF Modeler](https://mymodelrobot.appspot.com/5629499534213120). Here you can control the joint angles with sliders. \n",
    "\n",
    "Let's say we want to restrict the joint angles of the first joint to be between -90° and 90°. We can do this by setting the joint limits in the URDF file as:\n",
    "```\n",
    "<joint name=\"joint0\" type=\"revolute\">\n",
    "\t<joint name=\"joint0\" type=\"revolute\">  <!-- base -->\n",
    "    \t<parent link=\"link0\"/>\n",
    "    \t<child link=\"link1\"/>\n",
    "    \t<origin xyz=\"0 0 0.10\" rpy=\"0 0 0\"/>\n",
    "    \t<axis xyz=\"0 0 1\"/>\n",
    "    \t<limit lower=\"-1.5708\" upper=\"1.5708\" effort=\"0\" velocity=\"3\"/>\n",
    "</joint>\n",
    "```\n",
    "The following parameters are shown to solve the task but without much limitations:\n",
    "```\n",
    "joint0: -0.6 to 0.6\n",
    "joint1:  0   to 1.6\n",
    "joint3: -1.57 to 1.57\n",
    "joint5: -1.57 to 1.57\n",
    "joint7: -1.57 to 1.57\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a custom task.\n",
    "In the [panda-gym tutorial](https://panda-gym.readthedocs.io/en/latest/custom/custom_task.html) you can find a detailed description on how to create a custom task. However, we will create a new 3D environment for the given task of reaching a target position, hence ``SimpleReach``.\n",
    "\n",
    "#### Add Obstacles\n",
    "We will add some obstacles to the environment and work in the file: [envs/tasks/simple_reach.py](envs/tasks/simple_reach.py).\n",
    "\n",
    "The task has a function for creating the 3D pybullet environment:\n",
    "```\n",
    "    def _create_scene(self) -> None:\n",
    "        self.sim.create_plane(z_offset=-0.4)\n",
    "        self.sim.create_table(length=1.1, width=0.7, height=0.4, x_offset=-0.3)\n",
    "        self.sim.create_sphere(\n",
    "            body_name=\"target\",\n",
    "            radius=0.02,\n",
    "            mass=0.0,\n",
    "            ghost=True,\n",
    "            position=np.zeros(3),\n",
    "            rgba_color=np.array([0.1, 0.9, 0.1, 0.3]),\n",
    "        )\n",
    "```\n",
    "\n",
    "The box has a position of (x, y, z) = (0.1, 0.15, 0.0) and a half extent of (x, y, z) = (0.05, 0.05, 0.2. This means that our box has a shape of 5 cm x 5 cm x 20 cm. In order to see the obstacle, we have to set the rgba color of the box as well. We choose a grey color with an alpha value of 1.0 for now.The box also needs a unique name for the 3d scene and we choose ``box0``. At last, we set the mass of the box to a very high value, so that the box does not move: ``mass=10e11``.\n",
    "\n",
    "### Create Environment\n",
    "\n",
    "In order to use our new robot, we have to define it in an environment.\n",
    "So let's create a new environment. You can find the complete code under [envs/simple_env.py](envs/simple_env.py).\n",
    "\n",
    "We initizalize our new robot with a base position with and X offset of 45 cm.\\\n",
    "As control type, we use the action space of joint angles, hence ``joints``.\n",
    "The task is the reach task, which is defined in [envs/tasks/simple_reach.py](envs/tasks/simple_reach.py).\n",
    "\n",
    "```\n",
    "class SimpleEnv(RobotTaskEnv):\n",
    "    def __init__(self, render_mode):\n",
    "        sim = PyBullet(render_mode=render_mode)\n",
    "        robot = SimpleRobot(sim, control_type=\"joints\", base_position=[-0.45, 0, 0])\n",
    "        task = Reach(sim, robot.get_ee_position)\n",
    "        super().__init__(robot, task)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the new Robot in the new Environment\n",
    "We are now ready to test our new robot in the new environment with an obstacle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# Task: Panda Pick and Place with Obstacles #\n",
    "#############################################\n",
    "\n",
    "import gymnasium as gym\n",
    "import panda_gym\n",
    "from envs.simple_env import SimpleEnv\n",
    "from tqdm import tqdm\n",
    "from numpngw import write_apng\n",
    "\n",
    "# please choose one of the following render modes\n",
    "render_mode = 'human'       # opens OpenGL window for rendering\n",
    "#render_mode = 'rgb_array'  # returns RGB image as numpy array, if the render should be stored as animated png\n",
    "\n",
    "# create environment and activate rendering\n",
    "if render_mode == 'rgb_array':\n",
    "    images = [] # array to store images\n",
    "\n",
    "env = SimpleEnv(render_mode=render_mode)\n",
    "\n",
    "# define low frame rate for rendering to reduce computational load\n",
    "env.metadata['render_fps'] = 24\n",
    "\n",
    "# reset environment and get initial observation (either state of the joints or the end effector position)\n",
    "observation, info = env.reset()\n",
    "# define maximum number of episodes\n",
    "max_steps = 10000\n",
    "\n",
    "# run simulation \n",
    "for step in tqdm(range(max_steps)):\n",
    "    # take action as defined by our policy\n",
    "    action = env.action_space.sample()\n",
    "    \n",
    "    # execute action and get new observation, reward, termination flag and additional info\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    # add each image to our array for each step to create an animation afterwards\n",
    "    if render_mode == 'rgb_array':\n",
    "        images.append(env.render())\n",
    "\n",
    "    # when the episode is terminated, reset the environment\n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "\n",
    "env.close()\n",
    "\n",
    "if render_mode == 'rgb_array':\n",
    "    # save animation\n",
    "    print(\"Saving animation...\")\n",
    "    write_apng('images/simple_reach_w_obstacles.png', images, delay = 5)\n",
    "print(\"finished\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Animation of the new simple robot in an environment with an obstacle\n",
    "\n",
    "<img src=\"images/simple_reach_w_obstacles.png\" width=\"35%\"> \n",
    "\n",
    "As you can see, the robot is able to reach the target position even with an obstacle in the scene."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "1. At first we created a new robot model with the Universal Robot Description Format (URDF).\n",
    "    * [urdf/simple_robot.urdf](urdf/simple_robot.urdf).\n",
    "2. Then we imported the URDF file and parameterized the robot correctly.\n",
    "In here, we also defined the action space and functions for the status of the robot.\\\n",
    "We implemented how the robot takes the new action and how the observation is created.\n",
    "    * [robots/simple_robot.py](robots/simple_robot.py).\n",
    "3. After that, we restricted the action space (joint angles) to a reasonable range to make the task easier to solve.\n",
    "    * [urdf/simple_robot.urdf](urdf/simple_robot.urdf).\n",
    "4. A new task is defined to reach a target position, but with obstacles in the scene.\n",
    "    * [envs/tasks/simple_reach.py](envs/tasks/simple_reach.py).\n",
    "5. Finally, this new task and the new robot are combined in a new environment.\n",
    "    * [envs/simple_env.py](envs/simple_env.py)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0c5f67b466fc5386e183f274ffb84e1509e89581f809d6c238ca5386dca0c23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
